# ğŸ“‹ Plan de ImplementaciÃ³n: MigraciÃ³n SQLite + sqlite-vec

## Objetivo
Migrar el sistema de memoria de AEGEN de **Google File API** a **SQLite + sqlite-vec + FTS5**, manteniendo Redis para sesiones activas.

---

## ğŸ¯ Fases del Plan

### **FASE 0: PreparaciÃ³n (1-2 horas)**

| Tarea | DescripciÃ³n | VerificaciÃ³n |
|-------|-------------|--------------|
| 0.1 | Crear branch `feature/sqlite-memory` | `git branch -a \| grep sqlite` |
| 0.2 | AÃ±adir dependencias a `pyproject.toml`: `aiosqlite`, `sqlite-vec` | `pip install -e .` sin errores |
| 0.3 | Crear directorio `data/` para SQLite en raÃ­z | `ls data/` existe |
| 0.4 | AÃ±adir `data/*.db` a `.gitignore` | `grep "data/" .gitignore` |

---

### **FASE 1: Infraestructura SQLite (3-4 horas)**

| Tarea | Archivo | DescripciÃ³n |
|-------|---------|-------------|
| 1.1 | `src/memory/sqlite_store.py` | **CREAR** - Clase `SQLiteStore` con conexiÃ³n async |
| 1.2 | `src/memory/schema.sql` | **CREAR** - Esquema DDL (tables: memories, embeddings, sessions) |
| 1.3 | `src/memory/sqlite_store.py` | MÃ©todo `init_db()` que ejecuta schema.sql |
| 1.4 | `src/core/dependencies.py` | AÃ±adir `sqlite_connection` singleton |
| 1.5 | `src/core/config/base.py` | AÃ±adir `SQLITE_DB_PATH: str = "data/aegen_memory.db"` |

**Esquema propuesto (`schema.sql`):**
```sql
-- Tabla principal de memorias (texto + metadatos)
CREATE TABLE IF NOT EXISTS memories (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    chat_id TEXT NOT NULL,
    namespace TEXT DEFAULT 'user',  -- 'global' | 'user_{id}'
    content TEXT NOT NULL,
    content_hash TEXT UNIQUE,       -- SHA-256 para deduplicaciÃ³n
    memory_type TEXT,               -- 'fact', 'preference', 'conversation'
    metadata JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Ãndice FTS5 para bÃºsqueda por keywords
CREATE VIRTUAL TABLE IF NOT EXISTS memories_fts USING fts5(
    content,
    content='memories',
    content_rowid='id'
);

-- Triggers para mantener FTS sincronizado
CREATE TRIGGER IF NOT EXISTS memories_ai AFTER INSERT ON memories BEGIN
    INSERT INTO memories_fts(rowid, content) VALUES (new.id, new.content);
END;

-- Tabla vectorial (sqlite-vec)
CREATE VIRTUAL TABLE IF NOT EXISTS memory_vectors USING vec0(
    embedding FLOAT[768]  -- DimensiÃ³n de text-embedding-004
);

-- Mapeo vector -> memory
CREATE TABLE IF NOT EXISTS vector_memory_map (
    vector_rowid INTEGER PRIMARY KEY,
    memory_id INTEGER REFERENCES memories(id) ON DELETE CASCADE
);

-- Cache de embeddings
CREATE TABLE IF NOT EXISTS embedding_cache (
    content_hash TEXT PRIMARY KEY,
    embedding BLOB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**VerificaciÃ³n Fase 1:**
```bash
python -c "import aiosqlite; import sqlite_vec; print('OK')"
python -c "from src.memory.sqlite_store import SQLiteStore; print('OK')"
```

---

### **FASE 2: Pipeline de IngestiÃ³n (4-5 horas)**

| Tarea | Archivo | DescripciÃ³n |
|-------|---------|-------------|
| 2.1 | `src/memory/chunker.py` | **CREAR** - Chunker recursivo (400 tokens, 80 overlap) |
| 2.2 | `src/memory/embeddings.py` | **CREAR** - Wrapper para Google `text-embedding-004` API |
| 2.3 | `src/memory/deduplicator.py` | **CREAR** - Hash SHA-256 + verificaciÃ³n en cache |
| 2.4 | `src/memory/ingestion_pipeline.py` | **CREAR** - Orquestador: chunk â†’ dedupe â†’ embed â†’ store |
| 2.5 | `src/memory/sqlite_store.py` | MÃ©todos `insert_memory()`, `insert_vector()` |

**Chunker (`chunker.py`) - PseudocÃ³digo:**
```python
class RecursiveChunker:
    def __init__(self, chunk_size=400, overlap=80):
        self.chunk_size = chunk_size
        self.overlap = overlap

    def chunk(self, text: str, metadata: dict) -> list[dict]:
        # Dividir por pÃ¡rrafos primero, luego por oraciones si excede
        # Retornar lista de {"content": str, "metadata": dict}
```

**Embeddings (`embeddings.py`):**
```python
class EmbeddingService:
    async def embed(self, texts: list[str]) -> list[list[float]]:
        # Batch call a Google text-embedding-004
        # Usar cache local antes de llamar API
```

**VerificaciÃ³n Fase 2:**
```bash
pytest tests/unit/memory/test_chunker.py -v
pytest tests/unit/memory/test_embeddings.py -v
```

---

### **FASE 3: BÃºsqueda HÃ­brida (3-4 horas)**

| Tarea | Archivo | DescripciÃ³n |
|-------|---------|-------------|
| 3.1 | `src/memory/vector_search.py` | **CREAR** - KNN search con sqlite-vec |
| 3.2 | `src/memory/keyword_search.py` | **CREAR** - FTS5 search |
| 3.3 | `src/memory/hybrid_search.py` | **CREAR** - RRF ranking (0.7 vector + 0.3 keyword) |
| 3.4 | `src/memory/vector_memory_manager.py` | **REESCRIBIR** - Usar hybrid_search |

**RRF Ranking (`hybrid_search.py`):**
```python
def reciprocal_rank_fusion(
    vector_results: list[tuple[int, float]],  # (doc_id, score)
    keyword_results: list[tuple[int, float]],
    k: int = 60,
    vector_weight: float = 0.7,
    keyword_weight: float = 0.3
) -> list[int]:
    # Calcular RRF score para cada documento
    # Retornar doc_ids ordenados por score combinado
```

**VerificaciÃ³n Fase 3:**
```bash
pytest tests/integration/test_hybrid_search.py -v
```

---

### **FASE 4: Hooks de SesiÃ³n (2-3 horas)**

| Tarea | Archivo | DescripciÃ³n |
|-------|---------|-------------|
| 4.1 | `src/memory/session_processor.py` | **CREAR** - Procesa buffer al cerrar sesiÃ³n |
| 4.2 | `src/core/session_manager.py` | **MODIFICAR** - AÃ±adir hook `on_session_end()` |
| 4.3 | `src/memory/long_term_memory.py` | **MODIFICAR** - Reemplazar `file_search_tool` â†’ `ingestion_pipeline` |
| 4.4 | `src/memory/consolidation_worker.py` | **MODIFICAR** - Usar SQLite en lugar de Google Cloud |

**Flujo del Hook:**
```
SesiÃ³n Activa (Redis)
    â†“ [Timeout 30min o cierre explÃ­cito]
SessionProcessor.process(chat_id)
    â†“
1. Extraer buffer de Redis
2. LLM genera resumen/hechos
3. Chunker divide el contenido
4. Deduplicator filtra repetidos
5. EmbeddingService genera vectores
6. SQLiteStore persiste todo
7. Limpiar buffer Redis
```

**VerificaciÃ³n Fase 4:**
```bash
# Test end-to-end simulando cierre de sesiÃ³n
pytest tests/integration/test_session_hook.py -v
```

---

### **FASE 5: Limpieza de CÃ³digo Legacy (2 horas)**

| Tarea | Archivo | AcciÃ³n |
|-------|---------|--------|
| 5.1 | `src/tools/google_file_search.py` | **ELIMINAR** |
| 5.2 | `src/memory/cloud_gateway.py` | **ELIMINAR** |
| 5.3 | `src/memory/redis_fallback.py` | **ELIMINAR** |
| 5.4 | `src/memory/maintenance_job.py` | **ELIMINAR** |
| 5.5 | `src/memory/hybrid_coordinator.py` | **ELIMINAR** |
| 5.6 | `src/memory/consistency_manager.py` | **ELIMINAR** |
| 5.7 | `scripts/check_cloud_files.py` | **ELIMINAR** |
| 5.8 | `src/memory/knowledge_base.py` | **MODIFICAR** - Remover imports de cloud_gateway |
| 5.9 | `src/core/profile_manager.py` | **MODIFICAR** - Usar SQLite para persistencia de perfiles |
| 5.10 | Todos los archivos | `grep -r "file_search_tool\|cloud_gateway" src/` debe estar vacÃ­o |

**VerificaciÃ³n Fase 5:**
```bash
# No debe haber referencias a Google File API
grep -r "google_file_search\|cloud_gateway\|file_search_tool" src/
# Debe retornar vacÃ­o
```

---

### **FASE 6: Tests y ValidaciÃ³n (3-4 horas)**

| Tarea | DescripciÃ³n |
|-------|-------------|
| 6.1 | Crear `tests/unit/memory/test_sqlite_store.py` |
| 6.2 | Crear `tests/unit/memory/test_chunker.py` |
| 6.3 | Crear `tests/unit/memory/test_hybrid_search.py` |
| 6.4 | Crear `tests/integration/test_memory_e2e.py` |
| 6.5 | Ejecutar `make verify` completo |
| 6.6 | Test manual: enviar mensajes por Telegram, cerrar sesiÃ³n, verificar SQLite |

**Test E2E (`test_memory_e2e.py`):**
```python
async def test_full_memory_cycle():
    # 1. Simular 5 mensajes de usuario
    # 2. Triggear consolidaciÃ³n
    # 3. Buscar con query semÃ¡ntica
    # 4. Verificar que encuentra el contenido
    # 5. Buscar con keyword exacto
    # 6. Verificar resultados combinados
```

---

### **FASE 7: Respaldo Cloud (Opcional, post-MVP)**

| Tarea | DescripciÃ³n |
|-------|-------------|
| 7.1 | Crear `scripts/backup_to_gcs.py` |
| 7.2 | Configurar cron job diario para `sqlite3 backup` |
| 7.3 | Subir `.db` comprimido a Google Cloud Storage |

---

## ğŸ“ Estructura Final de `src/memory/`

```
src/memory/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ schema.sql              # DDL de SQLite
â”œâ”€â”€ sqlite_store.py         # ConexiÃ³n y operaciones SQLite
â”œâ”€â”€ chunker.py              # Chunking recursivo
â”œâ”€â”€ deduplicator.py         # Hash + cache
â”œâ”€â”€ embeddings.py           # Google text-embedding-004
â”œâ”€â”€ ingestion_pipeline.py   # Orquestador de ingestiÃ³n
â”œâ”€â”€ vector_search.py        # KNN con sqlite-vec
â”œâ”€â”€ keyword_search.py       # FTS5
â”œâ”€â”€ hybrid_search.py        # RRF ranking
â”œâ”€â”€ vector_memory_manager.py # API pÃºblica (reescrito)
â”œâ”€â”€ session_processor.py    # Hook de fin de sesiÃ³n
â”œâ”€â”€ long_term_memory.py     # Modificado
â”œâ”€â”€ consolidation_worker.py # Modificado
â”œâ”€â”€ knowledge_base.py       # Modificado
â”œâ”€â”€ redis_buffer.py         # Sin cambios
â”œâ”€â”€ fact_extractor.py       # Sin cambios
â”œâ”€â”€ memory_factory.py       # Modificado
â””â”€â”€ global_knowledge_loader.py # Modificado
```

---

## â±ï¸ EstimaciÃ³n Total

| Fase | Horas |
|------|-------|
| 0. PreparaciÃ³n | 1-2 |
| 1. Infraestructura SQLite | 3-4 |
| 2. Pipeline de IngestiÃ³n | 4-5 |
| 3. BÃºsqueda HÃ­brida | 3-4 |
| 4. Hooks de SesiÃ³n | 2-3 |
| 5. Limpieza Legacy | 2 |
| 6. Tests y ValidaciÃ³n | 3-4 |
| **TOTAL** | **18-24 horas** |

---

## â“ Preguntas para Ti Antes de Proceder

1. **Â¿Confirmas la dimensiÃ³n del embedding?** Google `text-embedding-004` usa 768 dimensiones. Â¿Esto estÃ¡ alineado con tu configuraciÃ³n actual?
2. **Â¿Quieres que `data/` estÃ© en la raÃ­z del proyecto o dentro de `src/`?**
3. **Â¿El modelo RAG actual (`gemini-2.5-flash-lite`) se usarÃ¡ solo para embeddings o tambiÃ©n para otros fines?** Necesito saber si debo mantener alguna referencia.
4. **Â¿Prefieres que empecemos por la Fase 1 (infraestructura) o quieres que primero escriba los tests (TDD)?**
