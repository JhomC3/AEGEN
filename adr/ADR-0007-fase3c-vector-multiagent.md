# ADR-0007: Fase 3C - Vector DB Multi-Tenant + Agentes Modulares

## Estado
**ACEPTADO** - Validado por consensus AI (3 modelos), implementar con approach por fases

## Contexto

### Situaci√≥n Actual (Fase 3B Completada)
- ‚úÖ Sistema conversacional funcional con ChatAgent ‚Üí MasterOrchestrator ‚Üí Specialists
- ‚úÖ Memoria Redis para sesiones conversacionales (TTL 1h)
- ‚ö†Ô∏è VectorMemoryManager como Interface/Stub (Pendiente implementaci√≥n real ChromaDB)
- ‚úÖ LangSmith observabilidad operacional

### Problema a Resolver
El branch `feature/phase3c-vector-multiagent` indica la direcci√≥n estrat√©gica, pero la implementaci√≥n actual de ChromaDB es insuficiente para escalar:

1. **No Multi-Tenancy**: Todos los usuarios comparten collection "telegram_data"
2. **Privacidad Comprometida**: Usuario A puede acceder datos de Usuario B
3. **Agentes R√≠gidos**: Especialistas actuales son espec√≠ficos, no modulares
4. **Memoria Limitada**: Solo Redis sesi√≥n, no contexto vectorial persistente

### Objetivo Fase 3C
Implementar base vectorial multi-tenant con agentes modulares que se compongan din√°micamente seg√∫n caso de uso.

## Decisi√≥n

### **Decisi√≥n 1: Multi-Tenant Vector Database (MODIFICADA - Approach Incremental)**

**FASE 1 - Adoptamos ChromaDB con metadata filtering (Semanas 1-3):**

```python
# Estructura collections simplificada
COLLECTIONS = {
    "user_{user_id}": "Toda data del usuario",
    "shared_knowledge": "Knowledge base compartida"
}

# Metadata filtering para data types
metadata = {
    "user_id": "123",
    "data_type": "conversation|document|preference",
    "session_id": "conv_456",
    "timestamp": "2025-08-25T10:00:00Z"
}
```

**FASE 2 - Evolution a collections granulares SI performance lo requiere (Semanas 7-8):**
```python
# Solo si testing demuestra necesidad
"user_123_conversations"     # Si > 10k items per user
"user_123_documents"         # Si documentos requieren embeddings diferentes
```

**Justificaci√≥n Revisada:**
- ‚úÖ **Start Simple**: Metadata filtering reduce operational overhead inicial
- ‚úÖ **Privacidad Garantizada**: Collection per user mantiene isolation
- ‚úÖ **Performance Validation**: Scale granular solo con data real
- ‚úÖ **Migration Path**: Clear evolution path si collection sprawl needed

### **Decisi√≥n 2: Agentes Modulares Componibles (MODIFICADA - Build Incremental)**

**FASE 1 - Interface Foundation (Semanas 1-3):**
```python
# Base interface robusta y extensible
class BaseModularAgent(Protocol):
    async def execute(self, input_data: Any, context: AgentContext) -> AgentResult
    def get_capabilities(self) -> List[str]
    def can_handle(self, task_type: str) -> bool
    # CR√çTICO: Interface debe ser estable desde el inicio
```

**FASE 2 - Core Agents (Semanas 4-6):**
```python
# Implementar SOLO 2 agentes bien dise√±ados primero
FileHandlerAgent      # Subida/validaci√≥n/parsing archivos
NLPParserAgent       # Procesamiento lenguaje natural

# NO implementar a√∫n:
# DataProcessorAgent, MemoryManagerAgent (Fase 3)
```

**FASE 3 - Composition Engine (Semanas 7-8):**
```python
# Solo despu√©s de validar agents individuales
class SimpleComposer:
    def compose_for_task(self, task_type: str) -> List[BaseModularAgent]
    # Start configuration-driven, evolve hacia dynamic orchestration
```

**Justificaci√≥n Revisada:**
- ‚úÖ **Interface First**: BaseModularAgent estable previene refactoring
- ‚úÖ **Prove Value**: 2 agents funcionando > 4 agents half-working
- ‚úÖ **Composition Later**: Solo compose cuando individual agents validated
- ‚úÖ **Avoid Over-Engineering**: Build complexity cuando se necesite, no before

### **Decisi√≥n 3: Hybrid Memory Architecture**

**Mantenemos Redis + a√±adimos Vector Memory:**

```python
# Redis: Memoria sesi√≥n corto plazo (1h TTL)
SessionMemory = {
    "conversation_state": {...},
    "active_agents": [...],
    "current_workflow": {...}
}

# ChromaDB: Memoria contexto largo plazo (persistente)
VectorMemory = {
    "conversation_embeddings": [...],
    "document_embeddings": [...], 
    "user_preferences": {...}
}
```

**Justificaci√≥n:**
- ‚úÖ **Best of Both**: Redis r√°pido para sesi√≥n, Vector para contexto sem√°ntico
- ‚úÖ **Performance**: No overload ChromaDB con datos temporales
- ‚úÖ **Consistency**: Redis proven, Vector DB complemento

### **Decisi√≥n 4: Agent Composition Engine (MODIFICADA - Simple First)**

**FASE 1-2 - Sequential Execution Simple (Semanas 1-6):**
```python
# NO AgentComposer complejo a√∫n - solo sequential execution
async def execute_file_workflow(file_data, user_id):
    context = AgentContext(user_id=user_id, ...)
    
    # Simple sequential execution
    parsed_file = await FileHandlerAgent().execute(file_data, context)
    analysis = await NLPParserAgent().execute(parsed_file, context)
    return analysis
```

**FASE 3 - Simple Composer (Semanas 7-8):**
```python
class SimpleComposer:
    """Configuration-driven composition, no dynamic orchestration yet."""
    
    WORKFLOWS = {
        "file_analysis": [FileHandlerAgent, NLPParserAgent],
        "chat": [NLPParserAgent],  # Start simple
        # Add more as needed, don't over-engineer
    }
    
    def compose_for_task(self, task_type: str) -> List[BaseModularAgent]
    async def execute_workflow(self, agents: List[BaseModularAgent], input_data, context)
```

**Justificaci√≥n Revisada:**
- ‚úÖ **Start Without Composition**: Sequential execution validates agents independently
- ‚úÖ **Configuration-Driven**: Simple workflows before dynamic orchestration  
- ‚úÖ **Prove Need**: Only add composition complexity when simple approach insufficient
- ‚úÖ **Incremental Complexity**: Build orchestration features when actual use cases require them

## Alternativas Consideradas

### **Alternativa A: Single Agent Approach (RECHAZADA)**
- Crear InventoryAgent monol√≠tico espec√≠fico
- **Problema**: No escalable, dif√≠cil de testear, no reutilizable

### **Alternativa B: PostgreSQL + pgvector (RECHAZADA)**  
- Cambiar ChromaDB por PostgreSQL con extensi√≥n vector
- **Problema**: Introduce nueva dependencia, ChromaDB ya funciona

### **Alternativa C: All-in-Redis (RECHAZADA)**
- Usar Redis para vector search con RediSearch
- **Problema**: Redis no optimizado para embeddings, overhead

## Consecuencias

### **Positivas**
- ‚úÖ **Privacidad**: Usuarios no pueden acceder datos de otros
- ‚úÖ **Escalabilidad**: Collections independientes escalan linealmente  
- ‚úÖ **Modularity**: Agentes reutilizables para m√∫ltiples casos de uso
- ‚úÖ **Performance**: B√∫squedas vectoriales en datasets user-specific menores
- ‚úÖ **Testing**: Componentes modulares m√°s f√°ciles de testear

### **Negativas**  
- ‚ùå **Complejidad**: M√°s componentes para mantener
- ‚ùå **Resource Usage**: M√°s collections = m√°s memoria ChromaDB
- ‚ùå **Migration**: Existing data en collection √∫nica debe migrarse

### **Riesgos**
- üî∂ **ChromaDB Limitations**: L√≠mites en n√∫mero de collections simult√°neas
- üî∂ **Agent Coordination**: Complejidad en manejo de errores entre agentes
- üî∂ **Context Consistency**: Mantener consistencia entre Redis y Vector Memory

## Plan de Implementaci√≥n (REVISADO - Approach Incremental)

### **Fase 1: Multi-Tenant Foundation + Interface Design (Semanas 1-3)**
**Objetivo**: Privacidad garantizada + interface estable
1. Extender `ChromaManager` con collections per-user + metadata filtering
2. Implementar `BaseModularAgent` interface (CR√çTICO: debe ser estable)
3. `VectorMemoryManager` b√°sico per-user
4. Migration script para data existente
5. Tests unitarios exhaustivos para foundation

### **Fase 2: Core Agents Implementation (Semanas 4-6)**  
**Objetivo**: 2 agentes funcionando perfectamente, no 4 half-working
1. Implementar `FileHandlerAgent` completo con validaci√≥n + parsing
2. Implementar `NLPParserAgent` con intent recognition b√°sico
3. Sequential execution workflows (NO composition engine yet)
4. Integration tests FileHandler ‚Üí NLP pipeline
5. Performance testing collection per-user

### **Fase 3: Simple Composition + Memory Integration (Semanas 7-8)**
**Objetivo**: Composition solo si agents individuales proven
1. `SimpleComposer` configuration-driven (NO dynamic orchestration)
2. Hybrid memory Redis + ChromaDB integration
3. Context retrieval optimization
4. E2E testing workflows completos
5. **Decision Point**: ¬øCollections granulares needed based on performance data?

### **Acceptance Criteria (REVISADO - Phased Validation)**

#### **Fase 1 - Foundation Must-Haves**
```bash
# Criterio 1: Multi-tenancy garantizado
user_123_data = vector_db.query(user_id="123", query="buscar conversaciones")
assert user_456_data not in user_123_data  # Isolation garantizado

# Criterio 2: Interface estable
agent = FileHandlerAgent()
result = await agent.execute(test_data, context)
assert isinstance(result, AgentResult)  # Interface consistent

# Criterio 3: Performance baseline
search_time = await vector_memory.search_user_context("123", "query")
assert search_time < 200_ms  # Relaxed initial target
```

#### **Fase 2 - Core Agents Must-Haves**
```bash
# Criterio 4: Individual agents funcionando
file_result = await FileHandlerAgent().execute(file_data, context)
assert file_result.success == True
nlp_result = await NLPParserAgent().execute(file_result.data, context) 
assert nlp_result.intent is not None

# Criterio 5: Sequential workflow
result = await execute_file_workflow(file_data, user_id="123")
assert result contains expected analysis
```

#### **Fase 3 - Composition Should-Haves**
```bash
# Criterio 6: Simple composition (only if Phase 2 successful)
workflow = composer.compose_for_task("file_analysis") 
assert FileHandlerAgent in workflow
assert NLPParserAgent in workflow

# Criterio 7: Memory integration
context = await memory_manager.get_user_context("123", "recent files")
assert len(context) > 0  # Context retrieval working
```

## Validaci√≥n

- [x] **Technical Review**: Consensus con m√∫ltiples modelos AI (COMPLETADO)
  - gemini-2.5-pro (critical): Over-engineering concerns, start simpler
  - gemini-2.0-flash-lite (neutral): Feasible but high complexity, phased approach
  - gemini-2.5-flash (optimistic): Strong architecture, careful implementation needed
- [x] **Architecture Review**: Consistency con patterns existentes AEGEN (COMPLETADO)
- [ ] **Performance Review**: Load testing con m√∫ltiples usuarios (Fase 1 deliverable)
- [ ] **Security Review**: Validation de user isolation (Fase 1 deliverable)

## Consensus AI Results

### **Key Agreements (All 3 models)**
- ‚úÖ Technically feasible with ChromaDB + Redis + modular agents
- ‚úÖ Significant user value from multi-tenancy + agent composition
- ‚úÖ Aligns with industry best practices for scalable AI systems
- ‚úÖ Hybrid memory (Redis + ChromaDB) is proven pattern

### **Key Concerns & Mitigations Adopted**
- ‚ö†Ô∏è **ChromaDB Collection Sprawl** ‚Üí Start with metadata filtering, evolve if needed
- ‚ö†Ô∏è **Over-Engineering Agent Composition** ‚Üí Build incrementally, prove value first
- ‚ö†Ô∏è **Implementation Complexity** ‚Üí Phased approach with validation gates
- ‚ö†Ô∏è **Premature Optimization** ‚Üí Address real problems with real performance data

### **Confidence Scores**
- Critical perspective: Concerns about complexity, recommends simplicity
- Neutral perspective: 7/10 - Feasible but requires careful execution
- Optimistic perspective: 8/10 - Strong architecture with proper implementation

---

**Decision Date**: 2026-01-22 (Revisado)
**Status**: ACEPTADO - En progreso (Fase 1: Foundation)
**Revisors**: Tech Lead, AI Consensus Models (gemini-2.5-pro, gemini-2.0-flash-lite, gemini-2.5-flash)  
**Next Review**: End of Fase 1 (Week 3) - Validate foundation before proceeding