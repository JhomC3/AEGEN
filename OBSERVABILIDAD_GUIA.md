# ğŸš€ GuÃ­a Super FÃ¡cil: CÃ³mo Ver las MÃ©tricas de AEGEN

*Una guÃ­a tan simple que hasta un niÃ±o de 7 aÃ±os puede hacerlo* ğŸ‘¶

---

## ğŸ¯ Â¿QuÃ© vamos a hacer?

Vamos a **espiar** a nuestro robot inteligente (AEGEN) para ver:
- Â¿CuÃ¡ntas veces habla con la IA? ğŸ¤–ğŸ’¬
- Â¿QuÃ© tan rÃ¡pido lo hace? âš¡
- Â¿CuÃ¡nto dinero gastamos? ğŸ’°
- Â¿EstÃ¡ funcionando bien? âœ…

---

## ğŸ”§ PASO 1: Encender Nuestro Robot

**Â¿QuÃ© hacer?**
Abre tu **terminal** (la pantalla negra donde escribes comandos) y escribe:

```bash
python -m src.main
```

**Â¿QuÃ© verÃ¡s?**
Un montÃ³n de texto que termina con algo como:
```
INFO: Uvicorn running on http://127.0.0.1:8000
INFO: FastAPI application 'AEGEN' configured and ready.
```

**ğŸ‰ Â¡Perfecto! Tu robot ya estÃ¡ despierto!**

---

## ğŸ” PASO 2: Ver Si Todo EstÃ¡ Bien

**Â¿QuÃ© hacer?**
En otra ventana de terminal (sin cerrar la primera), escribe:

```bash
curl http://localhost:8000/system/llm/health
```

**Â¿QuÃ© verÃ¡s?**
```json
{
  "status": "healthy",
  "metrics_collector": "operational",
  "timestamp": "2025-09-05T12:00:00Z"
}
```

**âœ… Si ves "healthy" = Â¡Todo funciona perfecto!**
**âŒ Si ves "unhealthy" = Algo estÃ¡ mal, pide ayuda**

---

## ğŸ“Š PASO 3: Ver el Estado del Robot

**Â¿QuÃ© hacer?**
Escribe este comando mÃ¡gico:

```bash
curl http://localhost:8000/system/llm/status
```

**Â¿QuÃ© verÃ¡s?**
```json
{
  "correlation_id": "abc12345",
  "active_calls": {"google:gemini-pro": 0.0},
  "total_calls_today": 0,
  "average_latency_ms": 0.0,
  "total_cost_today": 0.0,
  "status": "operational"
}
```

**ğŸ¤“ Â¿QuÃ© significa cada cosa?**
- `active_calls`: Â¿CuÃ¡ntas conversaciones estÃ¡ teniendo ahora?
- `total_calls_today`: Â¿CuÃ¡ntas veces hablÃ³ con la IA hoy?
- `average_latency_ms`: Â¿QuÃ© tan rÃ¡pido responde? (menos = mejor)
- `total_cost_today`: Â¿CuÃ¡nto dinero gastamos hoy?
- `status`: Â¿EstÃ¡ funcionando bien?

---

## ğŸ® PASO 4: Â¡Hacer que el Robot Trabaje!

**Â¿Por quÃ©?**
Ahora mismo el robot no ha hecho nada, asÃ­ que no hay mÃ©tricas. Â¡Vamos a darle trabajo!

**Â¿QuÃ© hacer?**
Simula un mensaje de Telegram que SÃ activa el sistema completo con observabilidad:

```bash
curl -X POST http://localhost:8000/api/v1/webhooks/telegram \
  -H "Content-Type: application/json" \
  -d '{
    "update_id": 123456,
    "message": {
      "message_id": 1,
      "from": {
        "id": 999999999,
        "is_bot": false,
        "first_name": "TestUser",
        "username": "testuser"
      },
      "chat": {
        "id": 999999999,
        "first_name": "TestUser",
        "username": "testuser",
        "type": "private"
      },
      "date": 1699999999,
      "text": "Hola! Explica quÃ© son los microservicios en 2 oraciones."
    }
  }'
```

**Â¿QuÃ© verÃ¡s?**
```json
{"task_id":"abc123-def456","message":"Telegram event accepted for processing."}
```

El sistema procesarÃ¡ tu mensaje usando el flujo completo con observabilidad.

---

## ğŸ”¬ PASO 5: Ver las MÃ©tricas Completas

**Â¿QuÃ© hacer?**
Ahora que el robot trabajÃ³, veamos sus mÃ©tricas:

```bash
curl http://localhost:8000/system/llm/metrics/summary
```

**Â¿QuÃ© verÃ¡s?**
```json
{
  "total_calls": 1,
  "total_tokens": 89,
  "average_latency_seconds": 3.2,
  "total_cost_usd": 0.0000891,
  "active_calls_count": 0
}
```

**ğŸ¤“ Â¿QuÃ© significa?**
- `total_calls`: Â¡El robot hablÃ³ 1 vez!
- `total_tokens`: UsÃ³ 89 "palabritas" para hablar (input + output)
- `average_latency_seconds`: TardÃ³ 3.2 segundos en responder
- `total_cost_usd`: Nos costÃ³ $0.0000891 (Â¡menos de una dÃ©cima de centavo!)
- `active_calls_count`: No estÃ¡ hablando ahora

---

## ğŸŒŸ PASO 6: Ver TODAS las MÃ©tricas (Modo Experto)

**Â¿QuÃ© hacer?**
Para ver TODO lo que el robot estÃ¡ midiendo:

```bash
curl http://localhost:8000/metrics
```

**Â¿QuÃ© verÃ¡s?**
Â¡Un montÃ³n de nÃºmeros! Busca las lÃ­neas que empiecen con `aegen_llm`:

```
aegen_llm_calls_total{provider="google",model="gemini-pro",status="success"} 1.0
aegen_llm_tokens_total{provider="google",model="gemini-pro",type="input"} 25.0
aegen_llm_tokens_total{provider="google",model="gemini-pro",type="output"} 20.0
```

---

## ğŸ‘€ PASO 7: Espiar en Tiempo Real

**Â¿QuÃ© hacer?**
Para ver cÃ³mo cambian las mÃ©tricas mientras el robot trabaja:

```bash
watch -n 2 'curl -s http://localhost:8000/system/llm/status | jq'
```

**Â¿QuÃ© verÃ¡s?**
La pantalla se actualizarÃ¡ cada 2 segundos mostrando las mÃ©tricas nuevas.

**Para salir:** Presiona `Ctrl + C`

---

## ğŸª PASO 8: Hacer que el Robot Trabaje Mucho

**Â¿QuÃ© hacer?**
Vamos a darle mÃ¡s trabajo para ver cÃ³mo cambian los nÃºmeros:

```bash
# Trabajo 1
curl -X POST http://localhost:8000/api/v1/analysis/ingest \
  -H "Content-Type: application/json" \
  -d '{"data": "Analiza: Bitcoin transaction 1"}'

# Trabajo 2
curl -X POST http://localhost:8000/api/v1/analysis/ingest \
  -H "Content-Type: application/json" \
  -d '{"data": "Analiza: Ethereum smart contract"}'

# Trabajo 3
curl -X POST http://localhost:8000/api/v1/analysis/ingest \
  -H "Content-Type: application/json" \
  -d '{"data": "Analiza: DeFi protocol data"}'
```

**Ahora mira las mÃ©tricas otra vez:**
```bash
curl http://localhost:8000/system/llm/status
```

**Â¡Los nÃºmeros habrÃ¡n cambiado!** ğŸ“ˆ

---

## ğŸ† PASO 9: Comandos de Emergencia

**Si algo sale mal:**

**ğŸ†˜ Ver si el robot sigue vivo:**
```bash
curl http://localhost:8000/system/llm/health
```

**ğŸ” Ver todos los endpoints disponibles:**
```bash
curl http://localhost:8000/docs
```
*(Abre tu navegador y ve a http://localhost:8000/docs)*

**ğŸ›‘ Parar el robot:**
En la terminal donde estÃ¡ corriendo, presiona `Ctrl + C`

---

## ğŸ“± PASO 10: Comandos SÃºper FÃ¡ciles

**Copia y pega estos comandos uno por uno:**

```bash
# 1. Ver estado general
curl http://localhost:8000/system/llm/status

# 2. Ver resumen de mÃ©tricas
curl http://localhost:8000/system/llm/metrics/summary

# 3. Comprobar salud
curl http://localhost:8000/system/llm/health

# 4. Dar trabajo al robot
curl -X POST http://localhost:8000/api/v1/analysis/ingest -H "Content-Type: application/json" -d '{"data": "test"}'

# 5. Ver mÃ©tricas completas
curl http://localhost:8000/metrics | grep aegen_llm
```

---

## ğŸ¨ Trucos Geniales

**ğŸ’¡ Hacer que sea mÃ¡s bonito:**
Si tienes `jq` instalado, puedes hacer que los nÃºmeros se vean mejor:
```bash
curl -s http://localhost:8000/system/llm/status | jq
```

**ğŸ’¡ Guardar las mÃ©tricas:**
```bash
curl -s http://localhost:8000/system/llm/status > mis_metricas.json
```

**ğŸ’¡ Ver solo lo importante:**
```bash
curl -s http://localhost:8000/metrics | grep aegen_llm_calls_total
```

---

## ğŸš¨ Â¿Problemas Comunes?

**âŒ "Connection refused"**
â†’ El robot no estÃ¡ encendido. Ve al PASO 1.

**âŒ "command not found: curl"**
â†’ En Windows usa: `Invoke-WebRequest http://localhost:8000/system/llm/status`

**âŒ NÃºmeros todos en 0**
â†’ El robot no ha trabajado. Ve al PASO 4.

**âŒ "unhealthy" en el health check**
â†’ Algo estÃ¡ roto. Reinicia el robot (PASO 1).

---

## ğŸ‰ Â¡Felicidades!

Â¡Ya sabes espiar a tu robot inteligente! ğŸ•µï¸â€â™€ï¸

Ahora puedes:
- âœ… Ver si estÃ¡ funcionando bien
- âœ… Saber cuÃ¡nto dinero gasta
- âœ… Ver quÃ© tan rÃ¡pido trabaja
- âœ… Contar cuÃ¡ntas veces usa la IA
- âœ… Detectar problemas antes que se vuelvan grandes

**Â¡Eres oficialmente un Inspector de Robots!** ğŸ…

---

*ğŸ“ Nota: Esta guÃ­a asume que tienes AEGEN corriendo en tu computadora local en el puerto 8000. Si usas otro puerto o servidor, cambia `localhost:8000` por la direcciÃ³n correcta.*